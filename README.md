# Wikipedia Scraper

The Python based web scraping tool called the Wikipedia Scraper is specifically created to retrieve information, from Wikipedia pages. The main objective of this project is to offer an effective method to collect data, from Wikipedia articles for different purposes.



## Features

- **Easy-to-Use:** Simple Python script for quick integration into your projects.
- **Customizable:** Adjustable settings for extracting specific information based on your requirements.
- **Robust:** Handles various Wikipedia page structures and formats.
- **Data Output:** Extracted data can be saved in different formats (e.g., JSON, CSV) for further analysis.

## Prerequisites
- Python 3.8
- Dependencies List -
- **Requests:** HTTP library for making web requests.
  - Install: `pip install requests`

- **Beautiful Soup:** HTML parsing library for pulling data out of HTML and XML files.
  - Install: `pip install beautifulsoup4`

- **Lxml:** XML and HTML parsing library for Python.
  - Install: `pip install lxml`

- **Selenium:** Browser automation tool for web scraping (useful for dynamic content).
  - Install: `pip install selenium`
## Acknowledgements

- **Requests:** The [Requests](https://docs.python-requests.org/en/latest/) library made it easy to handle HTTP requests in our scraper.

- **Beautiful Soup:** Special thanks to [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/) for providing a powerful tool for HTML parsing in Python.

- **Lxml:** Kudos to the [Lxml](https://lxml.de/) library, which significantly enhanced XML and HTML parsing capabilities in our project.

- **Selenium:** We appreciate the [Selenium](https://www.selenium.dev/) project for enabling browser automation, allowing us to scrape dynamically loaded content from Wikipedia pages.

## Contact
Email : mgmiteshgupta134@gmail.com

Linkedin : https://www.linkedin.com/in/mitesh-gupta/

Twitter : https://twitter.com/mg_mitesh

Medium : https://medium.com/@mgmiteshgupta134
